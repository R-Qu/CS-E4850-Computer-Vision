{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description:\n",
    "#   Exercise3 notebook.\n",
    "#\n",
    "# Copyright (C) 2018 Santiago Cortes, Juha Ylioinas\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "\n",
    "\n",
    "# Preparations\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from numpy.fft import fftshift, fft2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter, median_filter, map_coordinates\n",
    "from scipy.ndimage.filters import convolve as conv2\n",
    "from scipy.ndimage.filters import convolve1d as conv1\n",
    "\n",
    "from utils import rgb2gray, imnoise, add_gaussian_noise, gaussian2, affinefit\n",
    "\n",
    "# Select data directory\n",
    "\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-03-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 3\n",
    "The problems should be solved before the exercise session and solutions returned via\n",
    "MyCourses. Upload to MyCourses both: this Jupyter Notebook (.ipynb) file containing your solutions to the programming tasks and the exported pdf version of this Notebook file. If there are both programming and pen & paper tasks kindly combine the two pdf files (your scanned/LaTeX solutions and the exported Notebook) into a single pdf and submit that with the Notebook (.ipynb) file. <br><br> Note that (1) you are not supposed to change anything in the utils.py and (2) you should be sure that everything that you need to implement should work with the pictures specified by the assignments of this exercise round. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fill your name and student number below.\n",
    "\n",
    "Name:Rui Qu \n",
    "Student number:802619"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Image denoising\n",
    "\n",
    "In this exercise you will need to denoise the two example images using<br>\n",
    "a) Gaussian filtering, <br>\n",
    "b) median filtering, and <br>\n",
    "c) bilateral filtering (the latter two are explained in Section 3.3.1 of Szeliski’s book)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load test images.\n",
    "## Note: Must be double precision in the interval [0,1].\n",
    "im = rgb2gray(imread(data_dir+'/department2.jpg')) / 255.\n",
    "im = resize(im, (256, 256))\n",
    "\n",
    "## Add noise\n",
    "## \"salt and pepper\" noise\n",
    "imns = imnoise(im, 'salt & pepper', 0.05)\n",
    "## zero-mean gaussian noise\n",
    "imng = im + 0.05*np.random.randn(im.shape[0],im.shape[1])\n",
    "\n",
    "# Display original and noise corrupted images\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16,8))\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(im, cmap='gray')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(imns, cmap='gray')\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(imng, cmap='gray')\n",
    "ax[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Original, 'salt and pepper' and gaussian noise corrupted\", fontsize=20)\n",
    "plt.subplots_adjust(top=1.2)\n",
    "plt.show()\n",
    "\n",
    "## Don't worry about the possible warnings below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Gaussian filtering\n",
    "\n",
    "Gaussian Filter: $G_\\sigma=\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{(x^2+y^2)}{2\\sigma^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Gaussian filter of std 2.5 \n",
    "sigmad = 2.5\n",
    "g,_,_,_,_,_, = gaussian2(sigmad)\n",
    "\n",
    "gflt_imns = conv2(imns, g, mode='reflect')\n",
    "gflt_imng = conv2(imng, g, mode='reflect')\n",
    "\n",
    "## Instead of directly filtering with g, make a separable implementation\n",
    "## where you use horizontal and vertical 1D convolutions\n",
    "## That is, replace the above two lines, you can use conv1 instead\n",
    "## The result should not change.\n",
    "\n",
    "##--your-code-starts-here--##\n",
    "def gaussian_filter(sigma):\n",
    "    N = 2*np.maximum(4, np.ceil(6*sigma))+1\n",
    "    k = (N - 1) / 2.\n",
    "    x=np.linspace(-k,k+1,2*k+1)\n",
    "    g=1/(np.sqrt(2*np.pi)*sigma)*np.exp(-(x**2 / (2 * sigma ** 2)))\n",
    "    return g\n",
    "\n",
    "gflt = gaussian_filter(sigmad)\n",
    "\n",
    "gflt_imns_x = conv1(imns, gflt, axis=0, mode='reflect')\n",
    "gflt_imns_xy = conv1(gflt_imns_x, gflt, axis=1, mode='reflect')\n",
    "gflt_imns_y = conv1(imns, gflt, axis=1, mode='reflect')\n",
    "gflt_imns_yx = conv1(gflt_imns_y, gflt, axis=0, mode='reflect')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(13,8))\n",
    "fig.suptitle(\"Salt and Pepper Noise\", fontsize=16)\n",
    "\n",
    "axes[0,0].imshow(imns)\n",
    "axes[0,0].set_title(\"Original Salt and Pepper Noise\")\n",
    "axes[0,1].imshow(gflt_imns_x)\n",
    "axes[0,1].set_title(\"Convolving by x\")\n",
    "axes[0,2].imshow(gflt_imns_xy)\n",
    "axes[0,2].set_title(\"Convolving by x then y\")\n",
    "\n",
    "axes[1,0].imshow(imns)\n",
    "axes[1,0].set_title(\"Original Salt and Pepper Noise\")\n",
    "axes[1,1].imshow(gflt_imns_y)\n",
    "axes[1,1].set_title(\"Convolving by y\")\n",
    "axes[1,2].imshow(gflt_imns_yx)\n",
    "axes[1,2].set_title(\"Convolving by y then x\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "##--your-code-ends-here--##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gflt_imng_x = conv1(imng, gflt, axis=0, mode='reflect')\n",
    "gflt_imng_xy = conv1(gflt_imng_x, gflt, axis=1, mode='reflect')\n",
    "gflt_imng_y = conv1(imng, gflt, axis=1, mode='reflect')\n",
    "gflt_imng_yx = conv1(gflt_imng_y, gflt, axis=0, mode='reflect')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(13, 8))\n",
    "fig.suptitle(\"zero-mean gaussian noise\", fontsize=16)\n",
    "\n",
    "axes[0,0].imshow(imng)\n",
    "axes[0,0].set_title(\"Original zero-mean gaussian noise\")\n",
    "axes[0,1].imshow(gflt_imng_x)\n",
    "axes[0,1].set_title(\"Convolving by x\")\n",
    "axes[0,2].imshow(gflt_imng_xy)\n",
    "axes[0,2].set_title(\"Convolving by x then y\")\n",
    "\n",
    "axes[1,0].imshow(imng)\n",
    "axes[1,0].set_title(\"Original zero-mean gaussian noise\")\n",
    "axes[1,1].imshow(gflt_imng_y)\n",
    "axes[1,1].set_title(\"Convolving by y\")\n",
    "axes[1,2].imshow(gflt_imng_yx)\n",
    "axes[1,2].set_title(\"Convolving by y then x\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Median filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply median filtering, use neighborhood size 5x5\n",
    "\n",
    "##--your-code-starts-here--##\n",
    "\n",
    "def median_filter(image, filter_size):\n",
    "    temp = []\n",
    "    indexer = filter_size // 2\n",
    "    filtered_image = []\n",
    "    filtered_image = np.zeros((len(image),len(image[0])))\n",
    "    for i in range(len(image)):\n",
    "\n",
    "        for j in range(len(image[0])):\n",
    "\n",
    "            for z in range(filter_size):\n",
    "                if i + z - indexer < 0 or i + z - indexer > len(image) - 1:\n",
    "                    for c in range(filter_size):\n",
    "                        temp.append(0)\n",
    "                else:\n",
    "                    if j + z - indexer < 0 or j + indexer > len(image[0]) - 1:\n",
    "                        temp.append(0)\n",
    "                    else:\n",
    "                        for k in range(filter_size):\n",
    "                            temp.append(image[i + z - indexer][j + k - indexer])\n",
    "\n",
    "            temp.sort()\n",
    "            filtered_image[i][j] = temp[len(temp) // 2]\n",
    "            temp = []\n",
    "    return filtered_image\n",
    "\n",
    "medflt_imns= median_filter(imns,5)\n",
    "\n",
    "plt.imshow(medflt_imns)\n",
    "plt.title('Salt and Pepper Nois1e')\n",
    "plt.show()\n",
    "\n",
    "##--your-code-ends-here--##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medflt_imng= median_filter(imng,5)\n",
    "\n",
    "plt.imshow(medflt_imng)\n",
    "plt.title('Denoise zero-mean gaussian noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Bilateral filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_filter(img, wsize, sigma_d, sigma_r):\n",
    "    img = img.copy()\n",
    "    d = int(wsize/2)\n",
    "    for i in range(d, img.shape[0]-d):\n",
    "        for j in range(d, img.shape[1]-d):\n",
    "            sum_of_weights = 0\n",
    "            sum_of_weighted_pixels = 0\n",
    "            for steps in range(-1*d, d+1):\n",
    "                k, l = i+steps, j+steps \n",
    "                weights = np.exp(-1 * ((i-k)**2+(j-l)**2)/ (2 * sigma_d **2)) \\\n",
    "                        * np.exp(-1 * np.sqrt( (img[i][j]**2 - img[k][l]**2 )**2) / (2 * sigma_r ** 2))\n",
    "\n",
    "                sum_of_weights += weights\n",
    "                sum_of_weighted_pixels += img[k][l] * weights\n",
    "                \n",
    "            new_pixel = sum_of_weighted_pixels / sum_of_weights\n",
    "            img[i][j] = new_pixel\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Apply bilateral filter to each image and (uncomment the function calls once\n",
    "## its definition is ready)\n",
    "\n",
    "## You need to implement bilateralfilter function above.\n",
    "## Use formulas (3.34)-(3.37) from Szeliski's book.\n",
    "\n",
    "## Set bilateral filter parameters.\n",
    "wsize = 11\n",
    "sigma_d = 2.5\n",
    "sigma_r = 0.1\n",
    "\n",
    "bflt_imns = bilateral_filter(imns, wsize, sigma_d, sigma_r)\n",
    "bflt_imng = bilateral_filter(imng, wsize, sigma_d, sigma_r)\n",
    "\n",
    "# Display filtering results\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(16,8))\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(imns, cmap='gray')\n",
    "ax[0].set_title(\"Input image\")\n",
    "ax[1].imshow(gflt_imns, cmap='gray')\n",
    "ax[1].set_title(\"Result of gaussian filtering\")\n",
    "ax[2].imshow(medflt_imns, cmap='gray')\n",
    "ax[2].set_title(\"Result of median filtering\")\n",
    "ax[3].imshow(bflt_imns, cmap='gray')\n",
    "ax[3].set_title(\"Result of bilateral filtering\")\n",
    "ax[4].imshow(imng, cmap='gray')\n",
    "ax[5].imshow(gflt_imng, cmap='gray')\n",
    "ax[6].imshow(medflt_imng, cmap='gray')\n",
    "ax[7].imshow(bflt_imng, cmap='gray')\n",
    "plt.suptitle(\"Filtering results\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Hybrid images\n",
    "In  this  task  you  will  need  to  construct  a  hybrid  image  that  combines  facial images  of  a  wolf  and  a  man.  In  addition,  visualize  the  log  magnitudes  of  the  Fourier transforms  of  the  original  images  and  their  low-pass  and  high-pass  filtered  versions  (i.e.constituents  of  the  hybrid  image).<br><br>(Hint:  You  can  use  the  numpy.fft's  functions fft2 and fftshift as  shown  in  lecture  slides.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load test images\n",
    "man = imread(data_dir+'/man.jpg') / 255.\n",
    "wolf = imread(data_dir+'/wolf.jpg') / 255.\n",
    "\n",
    "# the pixel coordinates of eyes and chin have been manually found \n",
    "# from both images in order to enable affine alignment \n",
    "man_eyes_chin=np.array([[452, 461], [652, 457], [554, 823]])\n",
    "wolf_eyes_chin=np.array([[851, 919], [1159, 947], [975, 1451]])\n",
    "A, b = affinefit(man_eyes_chin, wolf_eyes_chin)\n",
    "\n",
    "xv, yv = np.meshgrid(np.arange(0, man.shape[1]), np.arange(0, man.shape[0]))\n",
    "pt = np.dot(A, np.vstack([xv.flatten(), yv.flatten()])) + np.tile(b, (xv.size,1)).T\n",
    "wolft = map_coordinates(wolf, (pt[1,:].reshape(man.shape), pt[0,:].reshape(man.shape)))\n",
    "\n",
    "## Below we simply blend the aligned images using additive superimposition\n",
    "additive_superimposition = man + wolft\n",
    "\n",
    "## Next we create two different Gaussian kernels for low-pass filtering\n",
    "## the two images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive blending by additive superimposition for illustration\n",
    "superimpose = man + wolft\n",
    "\n",
    "# low-pass filter the two images using two different Gaussian kernels\n",
    "sigmaA = 16\n",
    "sigmaB = 8\n",
    "man_lowpass = gaussian_filter(man, sigmaA, mode='nearest')\n",
    "wolft_lowpass = gaussian_filter(wolft, sigmaB, mode='nearest')\n",
    "# We use gaussian_filter above in this case as it is significantly faster than the way below\n",
    "#filterA,_,_,_,_,_, = gaussian2(sigmaA)\n",
    "#filterB,_,_,_,_,_, = gaussian2(sigmaB)\n",
    "#man_lowpass = conv2(man, filterA, mode='reflect')\n",
    "#wolft_lowpass = conv2(wolft, filterB, mode='reflect')\n",
    "\n",
    "## Your task is to create a hybrid image by combining a low-pass filtered \n",
    "## version of the human face with a high-pass filtered wolf face\n",
    " \n",
    "## HINT: You get a high-pass version by subtracting the low-pass filtered version\n",
    "## from the original image. Experiment also by trying different values for\n",
    "## 'sigmaA' and 'sigmaB' above.\n",
    " \n",
    "## Thus, your task is to replace the zero image on the following line\n",
    "## with a high-pass filtered version of 'wolft'\n",
    "wolft_highpass = np.zeros(man_lowpass.shape);\n",
    "\n",
    "##--your-code-starts-here--##\n",
    "\n",
    "wolft_highpass = wolft - wolft_lowpass\n",
    "\n",
    "##--your-code-ends-here--##\n",
    " \n",
    "## Replace also the zero image below with the correct hybrid image\n",
    "hybrid_image = np.zeros(man_lowpass.shape)\n",
    "\n",
    "##--your-code-starts-here--##\n",
    "\n",
    "hybrid_image = man_lowpass + wolft_highpass\n",
    "\n",
    "##--your-code-ends-here--##\n",
    " \n",
    "## Notice how strongly the interpretation of the hybrid image is affected \n",
    "## by the viewing distance\n",
    "\n",
    "## Display input images and both output images.\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16,8))\n",
    "plt.suptitle(\"Results of superimposition\", fontsize=20)\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(man, cmap='gray')\n",
    "ax[0].set_title(\"Input Image A\")\n",
    "ax[1].imshow(wolft, cmap='gray')\n",
    "ax[1].set_title(\"Input Image B\")\n",
    "ax[2].imshow(additive_superimposition, cmap='gray')\n",
    "ax[2].set_title(\"Additive Superimposition\")\n",
    "ax[3].imshow(hybrid_image, cmap='gray')\n",
    "ax[3].set_title(\"Hybrid Image\")\n",
    "plt.subplots_adjust(top=1.2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finally, visualize the log magnitudes of the Fourier\n",
    "## transforms of the original images\n",
    "\n",
    "##--your-code-starts-here--##\n",
    "\n",
    "F_man = fftshift(fft2(man))\n",
    "F_man_lowpass = fftshift(fft2(man_lowpass))\n",
    "F_wolft = fftshift(fft2(wolft))\n",
    "F_wolft_highpass = fftshift(fft2(wolft_highpass))\n",
    "\n",
    "##--your-code-ends-here--##\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16,8))\n",
    "plt.suptitle(\"Magnitudes of the Fourier transforms\", fontsize=20)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(np.log(np.abs(F_man)), cmap='gray')\n",
    "ax[0].set_title(\"log(abs(F_man))\")\n",
    "ax[1].imshow(np.log(np.abs(F_man_lowpass)), cmap='gray')\n",
    "ax[1].set_title(\"log(abs(F_man_lowpass)) image\")\n",
    "ax[2].imshow(np.log(np.abs(F_wolft)), cmap='gray')\n",
    "ax[2].set_title(\"log(abs(F_wolft)) image\")\n",
    "ax[3].imshow(np.log(np.abs(F_wolft_highpass)), cmap='gray')\n",
    "ax[3].set_title(\"log(abs(F_wolft_highpass))\")\n",
    "plt.subplots_adjust(top=1.2)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Image blending\n",
    "Go through the final part of this notebook and see the instructions in the comments of the source code. The example  implements Laplacian pyramid blending and blends facial images of a wolf and a man. The blending process is described  in Section 3.5.5 of Szeliski’s book. You need to implement the generation procedure for Gaussian and Laplacian image pyramids and the reconstruction procedure for reconstructing an image from its Laplacian pyramid.\n",
    "\n",
    "(Hint: You can use two 1D convolutions with the binomial filter kernel g = [1 4 6 4 1]/16\n",
    "to implement the low-pass filter before downsampling. Interpolation in the reconstruction\n",
    "procedure can be performed by adding zeros between the rows and columns of the lower\n",
    "resolution image and then filtering horizontally and\n",
    "vertically with the kernel 2g as mentioned in Figure 3.33 of Szeliski’s book.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implement missing functions: \n",
    "## generateLaplacianPyramid and reconstLaplacianPyramid\n",
    " \n",
    "## Notice that in this implementation the first level of a Gaussian pyramid \n",
    "## is the original image, and the last level of a Laplacian pyramid is the\n",
    "## same as the corresponding level in the Gaussian pyramid.\n",
    "\n",
    "man = imread(data_dir+'/man_color.jpg') / 255.\n",
    "man = resize(man, (int(man.shape[0] / 2), int(man.shape[1] / 2)))\n",
    "\n",
    "wolf = imread(data_dir+'/wolf_color.jpg') / 255.\n",
    "wolf = resize(wolf, (int(wolf.shape[0] / 2), int(wolf.shape[1] / 2)))\n",
    "\n",
    "# the pixel coordinates of eyes and chin have been manually found \n",
    "# from both images in order to enable affine alignment \n",
    "man_eyes_chin=np.array([[452, 461], [652, 457], [554, 823]])\n",
    "wolf_eyes_chin=np.array([[851, 919], [1159, 947], [975, 1451]])\n",
    "A, b = affinefit(man_eyes_chin, wolf_eyes_chin)\n",
    "\n",
    "xv, yv = np.meshgrid(np.arange(0, man.shape[1]), np.arange(0, man.shape[0]))\n",
    "pt = np.dot(A, np.vstack([xv.flatten(), yv.flatten()])) + np.tile(b, (xv.size, 1)).T\n",
    "\n",
    "wolft = np.zeros(man.shape)\n",
    "\n",
    "for ch in range(3):\n",
    "    wolft[:,:,ch] = map_coordinates(wolf[:,:,ch], (pt[1, :].reshape(man.shape[:2]),\n",
    "                               pt[0, :].reshape(man.shape[:2])))\n",
    "\n",
    "\n",
    "## Manually defined binary mask with an elliptical shape is constructed\n",
    "## as well as its complement\n",
    "x0=553.\n",
    "y0=680.\n",
    "a=160. \n",
    "b=190.\n",
    "pixmask = (((xv-x0) / a) ** 2 + ((yv-y0) / b) ** 2) < 1\n",
    "\n",
    "maskb = np.zeros(man.shape)\n",
    "maskbw = np.zeros(man.shape[:2])\n",
    "maskbw[pixmask] = 1.0\n",
    "for c in range(3):\n",
    "     maskb[:, :, c] = maskbw\n",
    "maska = 1.0 - maskb\n",
    "\n",
    "imga = resize(man, (1024,1024))\n",
    "imgb = resize(wolft, (1024, 1024))\n",
    "maska = resize(maska, (1024, 1024))\n",
    "maskb = resize(maskb, (1024, 1024))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLaplacianPyramid(im, ptype, levels):\n",
    "    ##--your-code-starts-here--##\n",
    "    im_copy = im.copy()\n",
    "    gaussianpyramid = [im]\n",
    "    laplacianpyramid = []\n",
    "\n",
    "    filter_kernel = 1/16 * np.array([1.0, 4.0, 6.0, 4.0, 1.0])\n",
    "\n",
    "    for i in range(levels):\n",
    "        # 1st conv with binomial filter\n",
    "        c1 = conv1(im_copy, filter_kernel, axis=0, mode=\"reflect\")\n",
    "        # 2nd conv with binomial filter\n",
    "        low_pass = conv1(c1, filter_kernel, axis=1, mode=\"reflect\")\n",
    "\n",
    "        im_copy = resize(low_pass, (int(im_copy.shape[0] / 2), int(im_copy.shape[1] / 2)), anti_aliasing=False)        \n",
    "        gaussianpyramid.append(im_copy)\n",
    "\n",
    "    for i in range(levels):\n",
    "        upscaled = resize(gaussianpyramid[i+1], gaussianpyramid[i].shape, anti_aliasing=False)\n",
    "        upscaled = conv1(conv1(upscaled, filter_kernel, axis=0), filter_kernel, axis=1)\n",
    "        difference = gaussianpyramid[i] - upscaled\n",
    "        laplacianpyramid.append(difference)\n",
    "\n",
    "    ##--your-code-ends-here--## \n",
    "    if ptype == 'laplacian':\n",
    "        return laplacianpyramid\n",
    "    elif ptype == 'gaussian':\n",
    "        return gaussianpyramid\n",
    "    else:\n",
    "        raise ValueError('Unknown pyramid type: ' + str(ptype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstLaplacianPyramid(lpyramid):\n",
    "    ##--your-code-starts-here--## \n",
    "    im = lpyramid[0][:]\n",
    "    shape = im.shape[0:2]    \n",
    "    filter_kernel = 1/16 * np.array([1.0, 4.0, 6.0, 4.0, 1.0])\n",
    "\n",
    "    for i in range(1, len(lpyramid)):\n",
    "        current_image = lpyramid[i]\n",
    "        resized_image = resize(current_image, shape, mode='reflect')\n",
    "\n",
    "        c1 = conv1(resized_image, filter_kernel, axis=0)\n",
    "        c2 = conv1(c1, filter_kernel, axis=1)\n",
    "        im += c2       \n",
    "    \n",
    "    ##--your-code-ends-here--## \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 8\n",
    " \n",
    "## Make Laplacian image pyramids with 8 levels.\n",
    "## Output is cell array (i.e. lpimga{i} is the Laplacian image at level i).\n",
    "## The image at the final level is the base level image from the\n",
    "## corresponding Gaussian pyramid.\n",
    "## In the version below the second input is either 'laplacian' or 'gaussian',\n",
    "## and it defines whether to output Laplacian or Gaussian pyramid.\n",
    "## After you have implemented the functions above you can uncomment the lines below\n",
    "## to finally plot the lacking figures ('Pyramid Blending' and 'Difference')\n",
    "lpimga = generateLaplacianPyramid(imga,'laplacian',level);\n",
    "lpimgb = generateLaplacianPyramid(imgb,'laplacian',level);\n",
    "\n",
    "## Just check that your pyramid and reconstruction both work\n",
    "ima = reconstLaplacianPyramid(lpimga)\n",
    "max_reconstruction_error = np.amax(np.abs(imga.flatten() - ima.flatten()))\n",
    "print(\"Reconstruction error: {}\".format(max_reconstruction_error))\n",
    "\n",
    "## Make Gaussian image pyramids of the mask images, maska and maskb\n",
    "gpmaska = generateLaplacianPyramid(maska,'gaussian',level);\n",
    "gpmaskb = generateLaplacianPyramid(maskb,'gaussian',level);\n",
    "\n",
    "# Make smooth masks in a simple manner for comparison\n",
    "smaska = gaussian_filter(maska, 20)\n",
    "smaskb = gaussian_filter(maskb, 20)\n",
    "\n",
    "## In practice, you can also use the Gaussian pyramids of smoothed masks. \n",
    "## In this case, the blendings (simple & pyramid) will appear more similar.\n",
    "gpsmaska = generateLaplacianPyramid(smaska,'gaussian',level); \n",
    "gpsmaskb = generateLaplacianPyramid(smaskb,'gaussian',level);\n",
    "\n",
    "limgo = {} # the blended pyramid\n",
    "for p in range(level):\n",
    "#    # Blend the Laplacian images at each level\n",
    "#    # (You can use either one of the two rows below.)\n",
    "    limgo[p] = (lpimga[p]*gpmaska[p] + lpimgb[p]*gpmaskb[p])/(gpmaska[p]+gpmaskb[p])\n",
    "    limgo[p] = (lpimga[p]*gpsmaska[p] + lpimgb[p]*gpsmaskb[p])/(gpsmaska[p]+gpsmaskb[p])\n",
    "\n",
    "## Reconstruct the blended image from its Laplacian pyramid  \n",
    "imgo = reconstLaplacianPyramid(limgo);\n",
    " \n",
    "## Simple blending with smooth masks\n",
    "imgo1 = smaska*imga + smaskb*imgb\n",
    "\n",
    "## Display results\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(16,8))\n",
    "plt.suptitle(\"Blending results\", fontsize=20)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(imga, cmap='gray')\n",
    "ax[0].set_title(\"Input Image A\")\n",
    "ax[1].imshow(imgb, cmap='gray')\n",
    "ax[1].set_title(\"Input Image B\")\n",
    "ax[2].set_visible(False)\n",
    "ax[3].imshow(imgo1, cmap='gray')\n",
    "ax[3].set_title(\"Simple Blending\")\n",
    "ax[4].imshow(imgo, cmap='gray')\n",
    "ax[4].set_title(\"Pyramid Blending\")\n",
    "ax[5].imshow(np.amax(imgo-imgo1, axis=2), cmap='gray')\n",
    "ax[5].set_title(\"Difference:\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
