{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true;\n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.input').hide();\n",
       "} else {\n",
       "$('div.input').show();\n",
       "}\n",
       "code_show = !code_show\n",
       "}\n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n",
      "Data stored in /coursedata/exercise-07-data\n"
     ]
    }
   ],
   "source": [
    "# Description:\n",
    "#   Exercise7 notebook.\n",
    "#\n",
    "# Copyright (C) 2018 Santiago Cortes, Juha Ylioinas\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "# Preparations\n",
    "import numpy as np\n",
    "\n",
    "# Select data directory\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-07-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 7\n",
    "\n",
    "#### Rui Qu 802619 \n",
    "\n",
    "The problems should be solved before the exercise session and solutions returned via\n",
    "MyCourses. <br><br> For this exercise round, upload this notebook(pdf and .ipynb versions) containing your source codes (for Exercise 1) and your answer to the question of Exercise2, and all the answers to the questions of Exercise 3 (VGG practical), see part[1-3].ipynb. Note that it's not necessary to upload part1.ipynb, part2.ipynb or part3.ipynb, because all of the necessary questions related to them are contained in this notebook and you're not expected to do any coding in Exercises 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Comparing  bags-of-words  with  tf-idf  weighting\n",
    "Assume  that  we  have  an  indexed  collection  of  documents  containing  the  five  terms  of the following table where the second row indicates the percentage of documents in which each term appears.<br>\n",
    "\n",
    "| term | cat | dog |mammals | mouse | pet |\n",
    "| --- | :---: | :---: | :---: | :---: | :---: |\n",
    "| **% of documents** | 5 | 20 | 2 | 10 | 60 |\n",
    "\n",
    "Now, given the query $Q=\\{mouse, cat, pet, mammals\\}$, compute the similarity between $Q$ and the following example documents $D1$, $D2$, $D3$, by using the cosine similarity measure and tf-idf weights (i.e. term frequency - inverse document frequency) for the bag-of-words histogram representations of the documents and the query.\n",
    "\n",
    "-  $D1$ = Cat is a pet, dog is a pet, and mouse may be a pet too.\n",
    "-  $D2$ = Cat, dog and mouse are all mammals.\n",
    "-  $D3$ = Cat and dog get along well, but cat may eat a mouse.\n",
    "\n",
    "Ignore other words except the five terms. You may proceed with the following steps:\n",
    "\n",
    "a) Compute and report the inverse document frequency (idf) for each of the five terms. Use the logarithm with base 2. (idf is the logarithm on slide 69 of Lecture 6.)<br>\n",
    "b) Compute the term frequencies for the query and each document. <br>\n",
    "c) Form the tf-idf weighted word occurrence histograms for the query and documents. <br>\n",
    "d) Evaluate the cosine similarity between the query and each document (i.e.\\ normalized scalar product between the weighted occurrence histograms as shown on slide 45).<br> \n",
    "e) Report the relative ranking of the documents. (You should get similarities 0.95, 0.64, and 0.63, but you need to determine which corresponds to which document.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>cat</th>\n",
       "      <th>pet</th>\n",
       "      <th>mammals</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mouse       cat   pet   mammals       dog\n",
       "0  0.250000  0.250000  0.25  0.250000  0.000000\n",
       "1  0.066667  0.066667  0.20  0.000000  0.066667\n",
       "2  0.142857  0.142857  0.00  0.142857  0.142857\n",
       "3  0.083333  0.166667  0.00  0.000000  0.083333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Comparing  bags-of-words  with  tf-idf  weighting\n",
    "##--your-code-starts-here--##\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class tf:\n",
    "    def __init__(self, text=None):\n",
    "        \n",
    "        if text is None:\n",
    "            text = {}\n",
    "        else:\n",
    "            self.text = text\n",
    "        self.text=text\n",
    "        \n",
    "        self.terms=['cat','dog','mammals','mouse','pet']\n",
    "    def extract(self, text):\n",
    "        extext=[]\n",
    "        for i in text.split():\n",
    "            if i in self.terms:\n",
    "                extext.append(i)\n",
    "        return extext\n",
    "        \n",
    "    def freq(self,text):\n",
    "        extract_text = self.extract(text)\n",
    "        frequency = collections.Counter(extract_text)\n",
    "        return frequency\n",
    "\n",
    "    def computeTF(self,text):\n",
    "        tfDict = {}\n",
    "        bowCount = len(text.split())\n",
    "        dict = self.freq(text)\n",
    "        for i in dict.items():\n",
    "            tfDict[i[0]] = i[1]/float(bowCount) \n",
    "        return tfDict   \n",
    "t=tf()\n",
    "\n",
    "q = \"mouse cat pet mammals\"\n",
    "d1 = \"cat is a pet dog is a pet and mouse may be a pet too\"\n",
    "d2 = \"cat dog and mouse are all mammals\"\n",
    "d3 = \"cat and dog get along well but cat may eat a mouse\"\n",
    "terms=['cat','dog','mammals','mouse','pet']\n",
    "\n",
    "pd.DataFrame([t.computeTF(q),t.computeTF(d1),t.computeTF(d2),t.computeTF(d3)]).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.99573227 1.60943791 3.91202301 2.30258509 0.51082562]\n",
      "[[0.74893307 0.19971548 0.42796175 0.49928871]\n",
      " [0.         0.10729586 0.2299197  0.13411983]\n",
      " [0.97800575 0.         0.55886043 0.        ]\n",
      " [0.57564627 0.15350567 0.32894073 0.19188209]\n",
      " [0.12770641 0.10216512 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf= pd.DataFrame([t.computeTF(q),t.computeTF(d1),t.computeTF(d2),t.computeTF(d3)]).fillna(0)\n",
    "\n",
    "tfidf=[]\n",
    "percent = np.array([5,20,2,10,60])\n",
    "idf = np.log(100 / percent)\n",
    "print(idf)\n",
    "\n",
    "tfidf.append(np.array(tf.cat)[:]*idf[0])\n",
    "tfidf.append(np.array(tf.dog)[:]*idf[1])\n",
    "tfidf.append(np.array(tf.mammals)[:]*idf[2])\n",
    "tfidf.append(np.array(tf.mouse)[:]*idf[3])\n",
    "tfidf.append(np.array(tf.pet)[:]*idf[4])\n",
    "\n",
    "tfidf=np.array(tfidf)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities: [0.95469481 0.64319374 0.62888464]\n"
     ]
    }
   ],
   "source": [
    "#plot bar-chart\n",
    "docslabel=['q','d1','d2','d3']\n",
    "docs=[eval(x) for x in docslabel]\n",
    "size = 4\n",
    "index = np.arange(size)\n",
    "total_width, n = 0.8, 5\n",
    "width = total_width / n\n",
    "index = index - (total_width - width) / 2\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(5):\n",
    "    if i==2:\n",
    "        plt.bar(index+i*width, tfidf[i], width=width, label=terms[i], tick_label=docslabel)\n",
    "    else:\n",
    "        plt.bar(index+i*width, tfidf[i], width=width, label=terms[i])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def evaluateSimilarity(query,docs):\n",
    "    evaluation=np.array([np.sum(query*doc)/(np.sqrt(np.sum(query**2))*np.sqrt(np.sum(doc**2))) for doc in docs])\n",
    "    srtArg= np.argsort(evaluation)[::-1]\n",
    "    srt = np.sort(evaluation)[::-1]\n",
    "    return [srtArg,srt]\n",
    "\n",
    "similarity = evaluateSimilarity(tfidf.T[0],tfidf.T[1:4,])\n",
    "\n",
    "print('Similarities:',similarity[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative ranking is $d2 > d3 > d1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Precision  and  recall\n",
    "There is a database of 10000 images and a user, who is only interested in images which contain a car. It is known that there are 500 such images in the database. An  automatic image retrieval system retrieves 300 car images and 50 other images from the database. Determine and report the precision and recall of the retrieval  system in this particularcase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here:\n",
    "\n",
    "$Recall=\\frac{True\\ positives}{Total\\ number\\ of\\ actual\\ positives}=\\frac{TP}{TP + FN}=\\frac{300}{300 + 50}=0.857$\n",
    "\n",
    "$Precision=\\frac{True\\ positives}{Total\\ number\\ of\\ positives\\ predicted}=\\frac{TP}{TP+FP}=\\frac{300}{500}=0.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - VGG practical on object instance recognition\n",
    "See the questions in part[1-3].ipynb and write your answers here.\n",
    "\n",
    "Part1:\n",
    "Stage I.A (two questions)\n",
    "Stage I.B (two questions)\n",
    "Stage I.C (one question)\n",
    "\n",
    "Part2 (one question)\n",
    "\n",
    "Part3:\n",
    "Stage III.A (three questions)\n",
    "Stage III.B (one question)\n",
    "Stage III.C (two questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answers here: \n",
    "\n",
    "Part1: Stage I.A\n",
    "\n",
    "1. In the second image, there're shade part in the left half of the buliding, while the right half is much brighter. In SIFT we aim to find Key locations, which are defined as maxima and minima of the result of difference of Gaussians function applied in scale space to a series of smoothed and resampled images. In this case it has limited influence on matching becaues the main features(e.g. edge of the building) is pretty clear. To avoid this problem we can introduce a modification of the k-d tree algorithm called the best-bin-first search method that can identify the nearest neighbors with high probability using only a limited amount of computation.\n",
    "\n",
    "2. It happens when image structure is non planar (not lying or able to be confined within a single plane : having a three-dimensional quality). Because SIFT computes an histogram of the gradient orientations in a Gaussian window with a standard deviation. This histogram is then smoothed and the maximum is selected. In addition to the biggest mode, up to other three modes whose amplitude is within the 80% of the biggest mode are retained and returned as additional orientations. \n",
    "\n",
    "Part1: Stage I.B\n",
    "\n",
    "1. Because the descriptor is highly distinctive and partially invariant to the remaining variations such as illumination, 3D viewpoint, etc. Orientation histograms are computed from magnitude and orientation values of samples in a 16×16 region around the keypoint such that each histogram contains samples from a 4×4 subregion of the original neighborhood region. Thus the discriptors are larger region (shown in blue) than the detection.\n",
    "\n",
    "2. It's because the high dimensionality of features may cause more dismatches than a database of local features. Changing light may not be a issue because, in general, SIFT is also robust to changes in illumination, noise, and minor changes in viewpoint. Generally probabilistic algorithms such as k-d trees with best bin first search can be used to remove mismatches.\n",
    "\n",
    "Part1: Stage I.C\n",
    "\n",
    "1. The best candidate match for each keypoint is found by identifying its nearest neighbor in the database of keypoints from training images. The nearest neighbors are defined as the keypoints with minimum Euclidean distance from the given descriptor vector. The probability that a match is correct can be determined by taking the ratio of distance from the closest neighbor to the distance of the second closest. Lowe rejected all matches in which the distance ratio is greater than 0.8, which eliminates 90% of the false matches while discarding less than 5% of the correct matches. \n",
    "\n",
    "Disparity gradient constraint and the RANSAC algorithm can be used to purify the matching points．\n",
    "\n",
    "Part2\n",
    "\n",
    "\n",
    "\n",
    "Part3: Stage III.A\n",
    "\n",
    "1. When original maxNumChecks=1014, Matches on quantized descriptors: 46 matches in 0.0241s Verified matches on quantized descriptors: 10 matches\n",
    "\n",
    "When I set maxNumChecks=16384, Matches on quantized descriptors: 46 matches in 0.0424s Verified matches on quantized descriptors: 10 matches\n",
    "\n",
    "Thus when the number of vocabulary and the time for computing decreases dramatically, the number of inliers only has a small reduction. So the difficulty for computing the transformation doesn't affected much by the size.\n",
    "\n",
    "2. Because the descriptor quantization for database images can be pre-computed, therefore it doesn't have to be part of execution time for a query.\n",
    "\n",
    "3. \n",
    "\n",
    "Part3: Stage III.B\n",
    "\n",
    "1. There 25 images sorted from largest score in the plots.  the top image is the same as the query image \n",
    "\n",
    "Part3: Stage III.C\n",
    "1. Because the score in this case is the number of inlier words\n",
    "2. The irrelevant images have lower score. So the retrieval results improved after geometric verification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
